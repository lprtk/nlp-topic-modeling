{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c92c6e",
   "metadata": {},
   "source": [
    "<strong>\n",
    "    <font color=\"#0E1117\">\n",
    "        Author: lprtk\n",
    "    </font>\n",
    "</strong>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "<Center>\n",
    "    <h1 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            NLP: topic modeling using word2vec & LDA\n",
    "        </font>\n",
    "    </h1>\n",
    "</Center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b48f1a",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddf328a",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Introduction & context\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695109dd",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "    The objective is to extract information and value from large volumes of textual data using Natural Language Processing (NLP). This notebook focuses on the use of the word2vec algorithm to represent and study the existing similarities between the words of several documents and on the combination of word2vec and the unsupervised learning algorithm LDA to perform topic modeling by grouping the documents by topic and by detailing the keywords of each document.\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e3d84",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e40822e",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Librairies import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaMulticore, Word2Vec\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "#from pyLDAvis import gensim_models\n",
    "#pyLDAvis.enable_notebook()\n",
    "from pyTCTK import TextNet, WordNet\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03510ce0",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce380664",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Data import\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8901d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(filepath_or_buffer=\"papers.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb45afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16348938",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7320a74",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Text cleaning\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9059e6e8",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify\">\n",
    "    We clean up the text in order to normalize it (lowercase, punctuation, etc.), remove all special characters and words that don't make sense or don't provide any information (stopwords) and then we transform words with a common root into a single word (lemmatization).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c50ff9",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Lowercase\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be28e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").lowercase()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7383d4c",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Punctuation\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_punctuation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae88f1",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            3) Specific cleaning\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1de588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2cb63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b449e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_digit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_mention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb51677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_single_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").additional_cleaning(\n",
    "    add_regexs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40827b0",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            4) Remove stopwords\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf7b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_stopword(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False,\n",
    "    add_stopwords=None,\n",
    "    remove_stopwords=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7001386",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            5) Lemmatization process\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = WordNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").lemmatize(\n",
    "    language=\"english\",\n",
    "    lowercase=False,\n",
    "    remove_accents=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8499a",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            6) Remove spaces\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1eec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = TextNet(\n",
    "    data=df_data,\n",
    "    column=\"text\"\n",
    ").remove_whitespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cac0b4",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            7) Tokenization process\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"text_tokenized\"] = df_data[\"text\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e62bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3aa468",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e53f00",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Vectorization using Word2vec\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b5f81",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Build model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d78c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    df_data[\"text_tokenized\"],\n",
    "    min_count=600,\n",
    "    window=10,\n",
    "    vector_size=250,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    workers=4,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a06f51",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Words similarity\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48563c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_words = w2v_model.wv.most_similar(\"estimator\")\n",
    "print(sim_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_words_2 = w2v_model.wv.most_similar(\"connectivity\")\n",
    "print(sim_words_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0681a4",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            3) Words visualisation\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "tokens = []\n",
    "\n",
    "for word in w2v_model.wv.key_to_index:\n",
    "    tokens.append(w2v_model.wv[w2v_model.wv.key_to_index])\n",
    "    labels.append(word)\n",
    "\n",
    "tsne_model = TSNE(perplexity=50, n_components=2, init=\"pca\", n_iter=2000, random_state=23)\n",
    "new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "plt.figure(figsize=(15, 13)) \n",
    "for i in range(len(x)):\n",
    "    plt.scatter(x[i],y[i])\n",
    "    plt.annotate(\n",
    "        labels[i],\n",
    "        xy=(x[i], y[i]),\n",
    "        xytext=(5, 2),\n",
    "        textcoords=\"offset points\",\n",
    "        ha=\"right\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7359a",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf1a54",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h2 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            Topic Modelling using LDA\n",
    "        </font>\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc240d8",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            1) Create dictionary\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60376e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "dictionary = corpora.Dictionary(df_data[\"text_tokenized\"])\n",
    "\n",
    "# term document frequency\n",
    "doc_term_matrix = [dictionary.doc2bow(paper) for paper in df_data[\"text_tokenized\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c940eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc_term_matrix[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# human readable format of corpus (term frequency)\n",
    "[[(dictionary[id2word], frequency) for id2word, frequency in corpus] for corpus in doc_term_matrix[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984abdcc",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            2) Build model\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752dc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaMulticore(\n",
    "    corpus=doc_term_matrix,\n",
    "    id2word=dictionary,\n",
    "    num_topics=4,\n",
    "    random_state=42,\n",
    "    chunksize=200,\n",
    "    passes=100,\n",
    "    per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e98bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237ece6",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            3) Topics' coherence\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model,\n",
    "    texts=df_data[\"text_tokenized\"],\n",
    "    dictionary=dictionary,\n",
    "    coherence=\"c_v\"\n",
    ")\n",
    "\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f\"Coherence score: {round(coherence_lda, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc769b",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            4) Topics' keywords\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bbc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colors = [\"#17C37B\", \"#F92969\", \"#FACA0C\", \"#0D1117\"]\n",
    "\n",
    "wc = WordCloud(\n",
    "    background_color=\"white\",\n",
    "    max_words=10,\n",
    "    max_font_size=300,\n",
    "    colormap=\"tab10\",\n",
    "    color_func=lambda *args, **kwargs: list_colors[i],\n",
    "    prefer_horizontal=1.0\n",
    ")\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharey=True, dpi=160)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    wc.generate_from_frequencies(topic_words)\n",
    "    plt.gca().imshow(wc)\n",
    "    plt.gca().set_title(\"Topic \"+str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis(\"off\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8a9de",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            5) Dominant topic for each document\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c8b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.DataFrame(\n",
    "    columns=[\"topic\", \"contribution\", \"keywords\"]\n",
    ")\n",
    "\n",
    "# get main topic in each document\n",
    "for i, list_rows in enumerate(lda_model[doc_term_matrix]):\n",
    "    row = list_rows[0] if lda_model.per_word_topics else list_rows\n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    \n",
    "    # get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        if j == 0:\n",
    "            wp = lda_model.show_topic(topic_num)\n",
    "            topic_keywords = \", \".join([word for word, prop in wp])\n",
    "            df_topics = df_topics.append(\n",
    "                dict(\n",
    "                    zip(\n",
    "                        df_topics.columns,\n",
    "                        [\n",
    "                            int(topic_num),\n",
    "                            round(prop_topic,4),\n",
    "                            topic_keywords\n",
    "                        ]\n",
    "                    )\n",
    "                ),\n",
    "                ignore_index=True\n",
    "            )\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# add original text to the end of the output\n",
    "df_topics = pd.concat([df_topics, df_data[\"text\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f885cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0dcb3d",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            6) Topics' distribution\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 13))\n",
    "plt.subplot(1, 1, 1)\n",
    "df_topics[\"topic\"].value_counts().plot(kind=\"bar\", color=\"#17C37B\",)\n",
    "plt.title(\"Topics' distribution by number of documents\", size=18)\n",
    "plt.xlabel(\"Topics\", size=16)\n",
    "plt.ylabel(\"Number of documents\", size=16)\n",
    "plt.xticks(rotation=0)\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88114a19",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            7) Topics' keywords\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[\"topic\"] = df_topics[\"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797158f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_colors = [\"#17C37B\", \"#F92969\", \"#FACA0C\", \"#0D1117\"]\n",
    "\n",
    "wc = WordCloud(\n",
    "    max_words=30,\n",
    "    min_font_size=10,\n",
    "    background_color=\"white\",\n",
    "    colormap=\"tab10\",\n",
    "    color_func=lambda *args, **kwargs: list_colors[i],\n",
    "    stopwords=None,\n",
    "    prefer_horizontal=1.0\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10), sharey=True, dpi=160)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    wc.generate(\n",
    "        str(df_data[df_data[\"topic\"]==i][\"text\"])\n",
    "    )\n",
    "    plt.gca().imshow(wc)\n",
    "    plt.gca().set_title(\"Topic \"+str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis(\"off\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.margins(x=0, y=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b8c86",
   "metadata": {},
   "source": [
    "<div style=\"margin: 10px;\">\n",
    "    <h3 style=\"font-family: Arial\">\n",
    "        <font color=\"#0E1117\">\n",
    "            8) Topics' visualization\n",
    "        </font>\n",
    "    </h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e69cd5",
   "metadata": {},
   "source": [
    "gensim_models.prepare(lda_model, doc_term_matrix, dictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
